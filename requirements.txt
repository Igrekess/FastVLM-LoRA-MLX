# FastVLM LoRA Fine-tuning Requirements
# Tested on Apple Silicon (M1/M2/M3/M4)

mlx>=0.21.0
mlx-vlm>=0.3.9
mlx-lm>=0.21.0
transformers>=4.40.0
huggingface-hub>=0.23.0
Pillow>=10.0.0
numpy>=1.24.0
safetensors>=0.4.0
